---
layout: post
title:  "DECEIVE - Low-effort Honeypot"
date:   2025-05-04 01:11:00 +0100
categories:
---

# DECEIVE - Low-effort Honeypot
I ran across this cool project on GitHub called DECEIVE (DECeption with Evaluative Integrated Validation Engine). AI is the buzzword and when you mix that with "honeypot", you got my interest. I'm going to try to not say "AI" in the rest of this post.

It's essentially a tool to simulate a realistic honeypot system through SSH. The interesting part here is that there is no real "system". No real files, no real accounts, no real processes. This means no set up on your part. You don't have to spin up a Linux box, create any files, or set up any users. An LLM of your choice will create a fake environment with users, directories, filenames (and contents in those 'files'), and other standard Linux artifacts. This is based on a prompt you provide to tell it what kind of system it should simulate. For example, this is the default prompt:

> You are a video game developer's system. Include realistic video game source and asset files.

When you connect to the SSH server, you'll find yourself in what appers to be a totally legitimate system. You may find other 'users' logged in, processes running, and you can explore the filesystem to find things that relate to the prompt you provided. Since this isn't a real Linux system, the LLM will simulate behaviours based on what the connected user asks for. For example, if you run an `ls` command, it will return the 'files' in the current working directory. It even has MOTDs, and warnings that the system is monitored. It's almost completely indistinguisable from a real box...

![Logging in, ls'ing, checking the users logged in](/assets/deceive-logging-in.png)

I'm exploring what it's capable of, and will update this page as I do. So far, I've been able to traverse through the filesystem, encountered realistic "You need sudo" situations, as well as telling me my user does not have permissions to use sudo commands. I've been able to print the contents of fake 'HR' documents which look pretty realistic.

![Looking at a file](/assets/deceive-looking-at-file.png)

Of course, not everything will be perfectly indistinguishable. Some things I've come across that give it away are:
- Trying to safely disconnect from the SSH system using a command will return a `XXX-END-OF-SESSION-XXX` message, but clicking enter puts you back into a command prompt. This makes sense because we're now trying to interact with the actual SSH session itself, where the LLM can only simulate things happening within its created environment.
- You can actually create a new user, give it sudo permissions, but when you try to log in as that user, you are met with the same response as above. Interestingly enough, pressing Enter doesn't give you a prompt back. You will keep getting the same `XXX-END-OF-SESSION-XXX` response. This wouldn't trick someone who knows what they're doing, and you also aren't logged into this fake user you created.
  - I tested exiting (using `CMD-C`) out of the SSH session and logging back in to see if my user still exists (with `cat etc/passwd`) and they do not. What's kind of funny is that if I pipe that command to a `grep 'tony'` ('tony' is the user I created), I get an output! The LLM has decided to show that 'tony' exists, under the full name "Tony Stark" which I never provided, LOL.

I also managed to kick a fake user out, which was entertaining. I somehow feel bad for John Doe, he was only trying to do his work :(
![Logging a user out](/assets/deceive-kicking-user.png)

All of this being said, none of this is real, so we can't actually expect a fully realistic interaction with this 'box'. It may make up users if we ellude to them existing, or... turn into a chatbot when I tell it to:

![Telling the LLM it should be a chatbot](/assets/deceive-you-are-a-chatbot.png)

I do appreciate it trying to stick to the script when I asked it for the weather, but it folded once I gave it the red pill.

Again, this isn't even a real system, and I think its honestly pretty impressive. It could totally fool a victim to the Honeypot, at least for some amount of time. I'm also sure you could improve the prompts and make it more resiliant to being 'escaped', or provide realistic outputs to commands you expect the victim to use. I think one of the more helpful uses of this is to generate realistic system logs. Everything you do is logged to a JSON file, which you can import into a data exploration tool of your choice and test things out without needing to set up a real system to create data.

I'm certainly curious to find some solid use cases for this, and I will update this post or create new ones if I do. Feel free to check it out, it's super easy to setup!

[GitHub - DECEIVE](https://github.com/splunk/DECEIVE)